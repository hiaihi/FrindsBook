import torch
import warnings
from PIL import Image
import random
from transformers import BlipProcessor, BlipForConditionalGeneration, MarianMTModel, MarianTokenizer
import importlib
import subprocess
import sys

# å¿½ç•¥ç‰¹å®šè­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, message="TypedStorage is deprecated")
warnings.filterwarnings("ignore", category=UserWarning, message="The parameter 'token_ids_1' is not used by this method")

# å…¨å±€å˜é‡
blip_processor = None
blip_model = None
translator_tokenizer = None
translator_model = None

# æœ‹å‹åœˆå¸¸ç”¨è¡¨æƒ…ç¬¦å·
EMOJIS = [
    "âœ¨", "ğŸŒŸ", "ğŸ’«", "â­", "ğŸŒˆ", "ğŸŒ¸", "ğŸŒº", "ğŸŒ¼", "ğŸŒ»", "ğŸŒ¹", 
    "ğŸ€", "ğŸŒ¿", "ğŸƒ", "ğŸŒ±", "ğŸŒ´", "ğŸŒµ", "ğŸŒ²", "ğŸ‚", "ğŸ", "ğŸ„",
    "ğŸŒŠ", "ğŸŒ…", "ğŸŒ„", "ğŸŒ‡", "ğŸŒ†", "ğŸŒƒ", "ğŸŒŒ", "ğŸŒ‰", "ğŸŒ", "ğŸŒ",
    "â¤ï¸", "ğŸ§¡", "ğŸ’›", "ğŸ’š", "ğŸ’™", "ğŸ’œ", "ğŸ–¤", "ğŸ¤", "ğŸ¤", "ğŸ’”",
    "ğŸ˜Š", "ğŸ˜ƒ", "ğŸ˜„", "ğŸ˜", "ğŸ˜†", "ğŸ˜", "ğŸ¥°", "ğŸ˜˜", "ğŸ˜—", "â˜ºï¸",
    "ğŸ™‚", "ğŸ¤—", "ğŸ¤”", "ğŸ¤­", "ğŸ¤«", "ğŸ¤¥", "ğŸ˜Œ", "ğŸ˜”", "ğŸ˜ª", "ğŸ¤¤",
    "ğŸ¥³", "ğŸ‰", "ğŸŠ", "ğŸˆ", "ğŸ", "ğŸ‚", "ğŸ°", "ğŸ§", "ğŸ­", "ğŸ¬",
    "ğŸ‘", "ğŸ‘", "ğŸ™Œ", "ğŸ¤", "ğŸ«¶", "ğŸ’ª", "âœŒï¸", "ğŸ¤", "ğŸ«°", "ğŸ¤Œ"
]

# æœ‹å‹åœˆå¸¸ç”¨æ ‡ç‚¹
PUNCTUATIONS = [
    "~", "!", "?", "...", "â€¦", ".", "ï¼Œ", "ã€‚", "ï¼", "ï¼Ÿ",
    "ï½", "ã€", "ï¼›", ":", "ï¼š", "'", "'", "\"", "\"", "ã€",
    "ã€‘", "ã€Œ", "ã€", "ã€", "ã€", "ï¼ˆ", "ï¼‰", "(", ")", "[",
    "]", "{", "}", "|" , "ï½œ", "Â·", "â€¢", "â—", "â—‹", "â—†",
    "ï¼ï¼ï¼", "ï¼Ÿï¼Ÿï¼Ÿ", "ï¼ï¼", "ï¼Ÿï¼Ÿ", "ï½ï½", "ï½ï½ï½", "...", "~~~"
]

# æ ‡ç­¾åˆ°æè¿°çš„æ˜ å°„
TAGS_MAP = {
    "è‡ªç„¶": ["å¤§è‡ªç„¶", "é£æ™¯", "è‡ªç„¶é£å…‰", "æˆ·å¤–", "æ¤ç‰©"],
    "åŸå¸‚": ["éƒ½å¸‚", "è¡—é“", "åŸå¸‚æ™¯è§‚", "å»ºç­‘", "ç°ä»£"],
    "äººç‰©": ["äººåƒ", "è‚–åƒ", "è¡¨æƒ…", "æƒ…æ„Ÿ", "äººç‰©ç‰¹å†™"],
    "ç¾é£Ÿ": ["é£Ÿç‰©", "é¤é¥®", "ç¾å‘³", "çƒ¹é¥ª", "ç”œç‚¹"],
    "åŠ¨ç‰©": ["å® ç‰©", "é‡ç”ŸåŠ¨ç‰©", "å¯çˆ±", "ç”Ÿç‰©", "åŠ¨ç‰©è¡Œä¸º"],
    "è‰ºæœ¯": ["åˆ›æ„", "è®¾è®¡", "è‰ºæœ¯ä½œå“", "æŠ½è±¡", "è‰²å½©"],
    "æ—…è¡Œ": ["æ—…æ¸¸", "æ¢é™©", "å¼‚å›½é£æƒ…", "åœ°æ ‡", "æ–‡åŒ–"],
    "æ—¥å¸¸": ["ç”Ÿæ´»", "æ—¥å¸¸åœºæ™¯", "å®¶åº­", "å·¥ä½œ", "ä¼‘é—²"]
}

# ä¸­æ–‡æœ‹å‹åœˆå¸¸ç”¨å‰ç¼€
CHINESE_PREFIXES = [
    "ä»Šæ—¥ä»½", "åˆ†äº«", "è®°å½•", "å‘ç°", "å¶é‡", "é‚‚é€…", 
    "äº«å—", "æ„Ÿå—", "æ²‰æµ¸åœ¨", "è¢«æ²»æ„ˆ", "é‡è§", "å¯»æ‰¾",
    "å“å‘³", "æ„Ÿæ‚Ÿ", "æ¢ç´¢", "æ¼«æ­¥", "é™äº«", "æ‚¦äº«",
    "å¿ƒåŠ¨", "å¿ƒæƒ…", "æ—¶å…‰", "å²æœˆ", "ç”Ÿæ´»", "æ—¥å¸¸",
    "æ¯æ—¥ä¸€æ‹", "éšæ‰‹æ‹", "æ‰“å¡", "æ™’ä¸€æ™’", "æ·±å¤œç‹¬äº«", "æ—©å®‰",
    "æ™šå®‰", "å‘¨æœ«", "å‡æ—¥", "åº¦å‡", "æ—…è¡Œ", "å‡ºæ¸¸",
    "å®è—", "æƒŠå–œ", "æ„å¤–", "å¹¸è¿", "å¹¸ç¦", "å¿«ä¹"
]

# ä¸­æ–‡æœ‹å‹åœˆå¸¸ç”¨åç¼€
CHINESE_SUFFIXES = [
    "çš„ç¬é—´", "çš„æ—¶å…‰", "çš„ç¾å¥½", "çš„æƒŠå–œ", "çš„å¿ƒæƒ…", 
    "çœŸå¥½", "å¥½å¼€å¿ƒ", "å¥½å¹¸ç¦", "å¥½ç¾", "å¥½èµ",
    "çš„æ„ŸåŠ¨", "çš„æ¸©æš–", "çš„æ²»æ„ˆ", "çš„è®°å¿†", "çš„å‘³é“",
    "çš„è‰²å½©", "çš„ä¸–ç•Œ", "çš„æ—…ç¨‹", "çš„æ•…äº‹", "çš„æ—¥å­",
    "å¤ªç¾äº†", "å¤ªèµäº†", "å¤ªæ²»æ„ˆäº†", "å¤ªå¹¸ç¦äº†", "å¤ªèˆ’æœäº†",
    "è¶…çº§æ£’", "è¶…çº§èµ", "è¶…çº§ç¾", "è¶…çº§çˆ±", "è¶…çº§å–œæ¬¢",
    "ç»ç»å­", "yyds", "å¤ªä¸Šå¤´äº†", "å¤ªç»äº†", "çˆ±äº†çˆ±äº†",
    "å¥½å–œæ¬¢å‘€", "å¥½æƒ³è¦", "å¥½æƒ³æ‹¥æœ‰", "å¥½æƒ³å»", "å¥½æƒ³è¯•è¯•"
]

# ä¸­æ–‡æœ‹å‹åœˆå¸¸ç”¨çŸ­è¯­
CHINESE_PHRASES = [
    "ç”Ÿæ´»ä¸æ­¢çœ¼å‰çš„è‹Ÿä¸”ï¼Œè¿˜æœ‰è¯—å’Œè¿œæ–¹",
    "å²æœˆé™å¥½ï¼Œç°ä¸–å®‰ç¨³",
    "ä¸€åˆ‡éƒ½åˆšåˆšå¥½",
    "å¹³å‡¡çš„æ—¥å­é‡Œè—ç€å°ç¡®å¹¸",
    "ç”Ÿæ´»è™½ç®€å•ï¼Œä½†å¤„å¤„æ˜¯ç¾å¥½",
    "æ„¿ä½ çœ¼ä¸­æœ‰æ˜Ÿè¾°ï¼Œå¿ƒä¸­æœ‰æš–é˜³",
    "ä¸è´ŸéŸ¶åï¼Œä¸è´Ÿè‡ªå·±",
    "äººé—´å€¼å¾—ï¼Œæœªæ¥å¯æœŸ",
    "æ¸©æŸ”ä¸”åšå®šï¼Œå‹‡æ•¢ä¸”è‡ªç”±",
    "æ„¿æ‰€æœ‰çš„ç¾å¥½å¦‚çº¦è€Œè‡³",
    "è¿™ä¸–ç•Œç¾å¥½ä¸ä½ ç¯ç¯ç›¸æ‰£",
    "äººç”Ÿå°±æ˜¯ä¸€åœºè¯´èµ°å°±èµ°çš„æ—…è¡Œ",
    "æ‰€æœ‰çš„ç›¸é‡éƒ½æ˜¯ä¹…åˆ«é‡é€¢",
    "è¿™é‡Œçš„é£æ™¯ç¾å¾—è®©äººå¿ƒé†‰",
    "ä»Šå¤©ä¹Ÿæ˜¯å…ƒæ°”æ»¡æ»¡çš„ä¸€å¤©",
    "ç”Ÿæ´»æ˜æœ—ï¼Œä¸‡ç‰©å¯çˆ±",
    "äººé—´çƒŸç«æ°”ï¼Œæœ€æŠšå‡¡äººå¿ƒ",
    "è¿™æ‰æ˜¯æˆ‘æƒ³è¦çš„ç”Ÿæ´»å•Š",
    "ä»Šæ—¥ä»½å¿«ä¹å·²ç­¾æ”¶",
    "è¿™æ³¢ç»ç»å­ï¼Œæ— äººèƒ½æ•Œ"
]

# ç½‘ç»œæµè¡Œè¯­
INTERNET_PHRASES = [
    "ç»ç»å­", "yyds", "çœŸçš„ä¼šè°¢", "å¤ªå¯äº†", "ç¬‘æ­»", 
    "awsl", "ä¸Šå¤´", "æœ‰è¢«æƒŠè‰³åˆ°", "é”æ­»", "æˆ‘çœŸçš„å“­æ­»",
    "å¤ªæ¬²äº†", "æˆ‘é…¸äº†", "æˆ‘å“­æ­»", "æˆ‘çœŸçš„æœäº†", "çˆ±äº†çˆ±äº†",
    "å†²é¸­", "å¤ªé¦™äº†", "ç¥ä»™æ‰“æ¶", "æˆ‘éƒ½å¯ä»¥", "å¤ªé¡¶äº†"
]

# æƒ…æ„Ÿè¯æ±‡
EMOTION_WORDS = [
    "æ„ŸåŠ¨", "æ²»æ„ˆ", "æ¸©æš–", "å¹¸ç¦", "å¿«ä¹", 
    "æƒŠå–œ", "æƒŠè‰³", "éœ‡æ’¼", "èˆ’é€‚", "æ”¾æ¾",
    "æ»¡è¶³", "å–œæ‚¦", "å¼€å¿ƒ", "æ¬£å–œ", "æ„‰æ‚¦",
    "ç¾å¥½", "ç¾å¦™", "ç¾ä¸½", "ç¾å‘³", "ç¾æ™¯"
]

def check_and_install_dependencies(dependencies):
    """æ£€æŸ¥å¹¶å®‰è£…ç¼ºå¤±çš„ä¾èµ–åŒ…"""
    missing_deps = []
    for dep in dependencies:
        try:
            importlib.import_module(dep)
            print(f"ä¾èµ– {dep} å·²å®‰è£…")
        except ImportError:
            missing_deps.append(dep)
            print(f"ä¾èµ– {dep} æœªå®‰è£…")
    
    if missing_deps:
        print(f"æ­£åœ¨å®‰è£…ç¼ºå¤±çš„ä¾èµ–: {', '.join(missing_deps)}")
        try:
            for dep in missing_deps:
                subprocess.check_call([sys.executable, "-m", "pip", "install", dep])
            print("ä¾èµ–å®‰è£…å®Œæˆ")
            return True
        except Exception as e:
            print(f"å®‰è£…ä¾èµ–å¤±è´¥: {str(e)}")
            return False
    return True

def load_blip_model():
    """åŠ è½½BLIPæ¨¡å‹"""
    global blip_processor, blip_model
    
    if blip_processor is None or blip_model is None:
        try:
            print("æ­£åœ¨åŠ è½½BLIPæ¨¡å‹...")
            # åŠ è½½æ¨¡å‹
            blip_processor = BlipProcessor.from_pretrained("models/blip-image-captioning-base")
            blip_model = BlipForConditionalGeneration.from_pretrained(
                "models/blip-image-captioning-base",
                torch_dtype=torch.float16  # ä½¿ç”¨åŠç²¾åº¦
                # low_cpu_mem_usage=True     # å‡å°‘CPUå†…å­˜ä½¿ç”¨
            )
            
            # å°†æ¨¡å‹ç§»è‡³GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
            device = "cuda" if torch.cuda.is_available() else "cpu"
            blip_model = blip_model.to(device)
            if device == "cpu":
                # å¦‚æœæ˜¯CPUï¼Œä½¿ç”¨float32
                blip_model = blip_model.float()
            print(f"BLIPæ¨¡å‹å·²åŠ è½½åˆ°{device}")
        except Exception as e:
            print(f"åŠ è½½BLIPæ¨¡å‹å¤±è´¥: {str(e)}")
            raise e

def generate_blip_caption(image):
    """ä½¿ç”¨BLIPæ¨¡å‹ç”Ÿæˆå›¾åƒæè¿°"""
    try:
        # ç¡®ä¿BLIPæ¨¡å‹å·²åŠ è½½
        try:
            load_blip_model()
        except Exception as e:
            print(f"BLIPæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            return None
        
        # å‡†å¤‡å›¾åƒ
        device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # ä½¿ç”¨BLIPå¤„ç†å™¨å¤„ç†å›¾åƒ
        try:
            inputs = blip_processor(image, return_tensors="pt").to(device, torch.float16)
        except Exception as e:
            print(f"BLIPå¤„ç†å›¾åƒå¤±è´¥: {str(e)}")
            return None
        
        # ç”Ÿæˆæè¿°
        try:
            with torch.no_grad():
                generated_ids = blip_model.generate(
                    **inputs,
                    max_length=50,
                    num_beams=5,
                    min_length=5,
                    top_p=0.9,
                    repetition_penalty=1.5
                )
                caption = blip_processor.decode(generated_ids[0], skip_special_tokens=True)
            
            return caption
        except Exception as e:
            print(f"BLIPç”Ÿæˆæè¿°å¤±è´¥: {str(e)}")
            return None
    except Exception as e:
        print(f"BLIPç”Ÿæˆæè¿°è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
        return None

def load_translator_model():
    """åŠ è½½MarianMTç¿»è¯‘æ¨¡å‹ï¼ˆè‹±æ–‡åˆ°ä¸­æ–‡ï¼‰"""
    global translator_tokenizer, translator_model
    
    if translator_tokenizer is None or translator_model is None:
        try:
            print("æ­£åœ¨åŠ è½½ç¿»è¯‘æ¨¡å‹...")
            # ä½¿ç”¨Helsinki-NLPçš„MarianMTæ¨¡å‹ï¼ˆè‹±æ–‡åˆ°ä¸­æ–‡ï¼‰
            model_name = "Helsinki-NLP/opus-mt-en-zh"
            translator_tokenizer = MarianTokenizer.from_pretrained(model_name)
            translator_model = MarianMTModel.from_pretrained(
                model_name,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                low_cpu_mem_usage=True
                # ç§»é™¤ä¸æ”¯æŒçš„device_map="auto"å‚æ•°
            )
            
            # å°†æ¨¡å‹ç§»è‡³GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
            device = "cuda" if torch.cuda.is_available() else "cpu"
            translator_model = translator_model.to(device)
            print(f"ç¿»è¯‘æ¨¡å‹å·²åŠ è½½åˆ°{device}")
        except Exception as e:
            print(f"åŠ è½½ç¿»è¯‘æ¨¡å‹å¤±è´¥: {str(e)}")
            raise e

def translate_text(text, max_length=100):
    """ä½¿ç”¨MarianMTæ¨¡å‹å°†è‹±æ–‡æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡"""
    try:
        # ç¡®ä¿ç¿»è¯‘æ¨¡å‹å·²åŠ è½½
        try:
            load_translator_model()
        except Exception as e:
            print(f"ç¿»è¯‘æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            return None
        
        # å‡†å¤‡è¾“å…¥
        device = "cuda" if torch.cuda.is_available() else "cpu"
        inputs = translator_tokenizer([text], return_tensors="pt", padding=True, truncation=True, max_length=max_length)
        inputs = inputs.to(device)
        
        # ç”Ÿæˆç¿»è¯‘
        try:
            with torch.no_grad():
                translated_ids = translator_model.generate(
                    **inputs,
                    max_length=max_length,
                    num_beams=4,
                    early_stopping=True,
                    no_repeat_ngram_size=3
                )
                translated_text = translator_tokenizer.batch_decode(translated_ids, skip_special_tokens=True)[0]
            
            return translated_text
        except Exception as e:
            print(f"ç¿»è¯‘ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    except Exception as e:
        print(f"ç¿»è¯‘è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
        return None

def enhance_with_glm(caption, style="æœ‹å‹åœˆ"):
    """ä½¿ç”¨è§„åˆ™å¢å¼ºæè¿°æ–‡æœ¬ï¼ˆæ›¿ä»£åŸæ¥çš„GLMæ¨¡å‹ï¼‰"""
    # ç›´æ¥è°ƒç”¨è§„åˆ™å¢å¼ºæ–¹æ³•
    return enhance_with_rules(caption, style)

def enhance_with_rules(caption, style="æœ‹å‹åœˆ"):
    """ä½¿ç”¨è§„åˆ™å¢å¼ºæè¿°æ–‡æœ¬"""
    # ç®€å•çš„æ–‡æœ¬å¢å¼ºè§„åˆ™
    if style == "æœ‹å‹åœˆ":
        # 1. å°è¯•å°†è‹±æ–‡æè¿°ç¿»è¯‘æˆä¸­æ–‡
        english_words = ["a", "the", "is", "are", "in", "on", "with", "and", "of"]
        is_english = any(word in english_words for word in caption.lower().split())
        
        if is_english:
            # ä½¿ç”¨ç¿»è¯‘æ¨¡å‹å°†è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡
            translated_text = translate_text(caption)
            if translated_text:
                caption = translated_text
            else:
                # å¦‚æœç¿»è¯‘å¤±è´¥ï¼Œå›é€€åˆ°åŸæ¥çš„è§„åˆ™æ›¿æ¢æ–¹æ³•
                if random.random() < 0.3:  # 30%æ¦‚ç‡ä½¿ç”¨å®Œæ•´çŸ­è¯­
                    return random.choice(CHINESE_PHRASES)
                else:
                    # 70%æ¦‚ç‡ä½¿ç”¨å‰ç¼€+åç¼€ç»„åˆ
                    return random.choice(CHINESE_PREFIXES) + "ï¼Œ" + random.choice(CHINESE_SUFFIXES)
        
        # 2. æˆªæ–­é•¿å¥å­
        if len(caption) > 30:
            words = caption.split()
            caption = ' '.join(words[:min(10, len(words))])
        
        # 3. æ·»åŠ å¸¸è§çš„æœ‹å‹åœˆè¡¨è¾¾
        if random.random() < 0.9:  # æé«˜åˆ°90%çš„æ¦‚ç‡æ·»åŠ 
            choice = random.random()
            if choice < 0.4:  # 40%æ¦‚ç‡æ·»åŠ å‰ç¼€
                caption = random.choice(CHINESE_PREFIXES) + "ï¼Œ" + caption
            elif choice < 0.8:  # 40%æ¦‚ç‡æ·»åŠ åç¼€
                caption = caption + "ï¼Œ" + random.choice(CHINESE_SUFFIXES)
            else:  # 20%æ¦‚ç‡åŒæ—¶æ·»åŠ å‰ç¼€å’Œåç¼€
                caption = random.choice(CHINESE_PREFIXES) + "ï¼Œ" + caption + "ï¼Œ" + random.choice(CHINESE_SUFFIXES)
        
        # 4. æ·»åŠ ç½‘ç»œæµè¡Œè¯­
        if random.random() < 0.3:  # 30%æ¦‚ç‡æ·»åŠ ç½‘ç»œæµè¡Œè¯­
            if random.random() < 0.5:  # 50%æ¦‚ç‡åœ¨å¼€å¤´æ·»åŠ 
                caption = random.choice(INTERNET_PHRASES) + "ï¼" + caption
            else:  # 50%æ¦‚ç‡åœ¨ç»“å°¾æ·»åŠ 
                caption = caption + "ï¼Œ" + random.choice(INTERNET_PHRASES) + "ï¼"
        
        # 5. æ·»åŠ æƒ…æ„Ÿè¯æ±‡
        if random.random() < 0.4:  # 40%æ¦‚ç‡æ·»åŠ æƒ…æ„Ÿè¯æ±‡
            emotion = random.choice(EMOTION_WORDS)
            if random.random() < 0.5:  # 50%æ¦‚ç‡ä½œä¸ºå½¢å®¹è¯
                caption = caption.replace("ï¼Œ", "ï¼Œå¥½" + emotion + "ï¼Œ", 1)
            else:  # 50%æ¦‚ç‡ä½œä¸ºæ„Ÿå¹
                caption = caption + "ï¼ŒçœŸæ˜¯å¤ª" + emotion + "äº†ï¼"
        
        # 6. éšæœºä½¿ç”¨å®Œæ•´çŸ­è¯­æ›¿æ¢
        if random.random() < 0.15:  # 15%æ¦‚ç‡å®Œå…¨æ›¿æ¢ä¸ºçŸ­è¯­
            return random.choice(CHINESE_PHRASES)
    else:
        # æ™®é€šæè¿°ï¼Œä¿æŒåŸæ ·
        pass
    
    return caption

def add_moments_style(text):
    """æ·»åŠ æœ‹å‹åœˆé£æ ¼å…ƒç´ """
    # éšæœºæ·»åŠ è¡¨æƒ…ç¬¦å·
    if random.random() < 0.95:  # æé«˜åˆ°95%çš„æ¦‚ç‡æ·»åŠ è¡¨æƒ…
        num_emojis = random.randint(1, 4)  # å¢åŠ å¯èƒ½çš„è¡¨æƒ…æ•°é‡
        emojis = random.sample(EMOJIS, num_emojis)
        
        # åœ¨æ–‡æœ¬å¼€å¤´æˆ–ç»“å°¾æ·»åŠ è¡¨æƒ…ï¼Œæˆ–è€…åŒæ—¶æ·»åŠ 
        choice = random.random()
        if choice < 0.4:  # 40%æ¦‚ç‡åœ¨å¼€å¤´æ·»åŠ 
            text = "".join(emojis) + " " + text
        elif choice < 0.8:  # 40%æ¦‚ç‡åœ¨ç»“å°¾æ·»åŠ 
            text = text + " " + "".join(emojis)
        else:  # 20%æ¦‚ç‡åœ¨å¼€å¤´å’Œç»“å°¾éƒ½æ·»åŠ 
            start_emojis = random.sample(EMOJIS, random.randint(1, 2))
            end_emojis = random.sample(EMOJIS, random.randint(1, 2))
            text = "".join(start_emojis) + " " + text + " " + "".join(end_emojis)
    
    # éšæœºæ›¿æ¢æ ‡ç‚¹
    if random.random() < 0.6:  # æé«˜åˆ°60%çš„æ¦‚ç‡æ›¿æ¢æ ‡ç‚¹
        for punct in ["ã€‚", ".", "!", "ï¼"]:
            if punct in text:
                replacement = random.choice(["~", "...", "â€¦", "ï¼", "~", "ï¼ï¼", "ï¼ï¼ï¼", "~~~"])
                text = text.replace(punct, replacement, 1)
    
    # æ·»åŠ æ„Ÿå¹è¯
    if random.random() < 0.3:  # 30%æ¦‚ç‡æ·»åŠ æ„Ÿå¹è¯
        exclamations = ["å“‡", "å•Š", "å—¯", "å“¦", "å‘€", "å‘œ", "å˜¿", "å“å‘€", "å¤©å‘", "æˆ‘çš„å¤©"]
        exclamation = random.choice(exclamations) + random.choice(["ï¼", "~", "~~"])
        if random.random() < 0.5:  # 50%æ¦‚ç‡åœ¨å¼€å¤´æ·»åŠ 
            text = exclamation + " " + text
        else:  # 50%æ¦‚ç‡åœ¨ç»“å°¾æ·»åŠ 
            text = text + " " + exclamation
    
    return text

def process_image(image):
    """å¤„ç†å›¾åƒå¹¶ç”Ÿæˆæè¿°"""
    # ä½¿ç”¨BLIPæ¨¡å‹ç”Ÿæˆå›¾åƒæè¿°
    blip_caption = generate_blip_caption(image)
    
    if not blip_caption:
        return {
            'success': False,
            'message': 'å›¾åƒæè¿°ç”Ÿæˆå¤±è´¥'
        } 
    
    # ä½¿ç”¨è§„åˆ™å¢å¼ºæè¿°
    try:
        enhanced_caption = enhance_with_rules(blip_caption, "æœ‹å‹åœˆ")
        final_caption = add_moments_style(enhanced_caption)
        
        # ç”Ÿæˆç›¸å…³æ ‡ç­¾
        suggested_tags = []
        try:
            for category, tags in TAGS_MAP.items():
                if any(keyword.lower() in blip_caption.lower() for keyword in [category.lower()] + [tag.lower() for tag in tags]):
                    suggested_tags.extend(random.sample(tags, min(2, len(tags))))
            
            # ç¡®ä¿æ ‡ç­¾ä¸é‡å¤ä¸”æ•°é‡åˆé€‚
            suggested_tags = list(set(suggested_tags))[:3]
        except Exception as e:
            print(f"ç”Ÿæˆæ ‡ç­¾å¤±è´¥: {str(e)}")
            # æ ‡ç­¾ç”Ÿæˆå¤±è´¥ä¸å½±å“ä¸»è¦åŠŸèƒ½
        
        return {
            'success': True,
            'generatedText': final_caption,
            'originalCaption': blip_caption,
            'enhancedCaption': enhanced_caption,
            'suggestedTags': suggested_tags,
            'model': 'BLIP+ç¿»è¯‘+è§„åˆ™å¢å¼º'
        }
    except Exception as e:
        print(f"å¤„ç†å›¾åƒæè¿°è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        # å¦‚æœå¢å¼ºå¤±è´¥ï¼Œè¿”å›åŸå§‹BLIPæè¿°
        try:
            styled_caption = add_moments_style(blip_caption)
        except Exception:
            # å¦‚æœé£æ ¼åŒ–ä¹Ÿå¤±è´¥ï¼Œç›´æ¥è¿”å›åŸå§‹æè¿°
            styled_caption = blip_caption
            
        return {
            'success': True,
            'generatedText': styled_caption,
            'originalCaption': blip_caption,
            'suggestedTags': [],
            'model': 'BLIP',
            'error': str(e)
        }